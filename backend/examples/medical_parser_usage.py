"""
åŒ»å­¦æ–‡æ¡£è§£æå™¨ä½¿ç”¨ç¤ºä¾‹
Medical Parser Usage Examples
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.medical_parser import (
    parse_medical_document,
    create_document_chunks,
    HierarchicalMedicalParser
)
from app.core.logger import get_logger

logger = get_logger(__name__)


async def basic_usage_example():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    # å‡è®¾æœ‰ä¸€ä¸ªåŒ»å­¦æ–‡æ¡£æ–‡ä»¶
    file_path = "examples/hypertension_guideline.pdf"

    # 1. è§£æåŒ»å­¦æ–‡æ¡£
    try:
        print(f"æ­£åœ¨è§£ææ–‡æ¡£: {file_path}")
        document = await parse_medical_document(file_path)

        print(f"âœ… è§£ææˆåŠŸ!")
        print(f"æ–‡æ¡£ID: {document.document_id}")
        print(f"æ–‡æ¡£ç±»å‹: {document.metadata.file_type}")
        print(f"å­—ç¬¦æ•°: {document.metadata.char_count:,}")
        print(f"ç« èŠ‚æ•°: {len(document.sections)}")
        print(f"è¡¨æ ¼æ•°: {len(document.tables)}")
        print(f"ç®—æ³•æ•°: {len(document.algorithms)}")

    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        return

    # 2. æŸ¥çœ‹æ–‡æ¡£ç« èŠ‚
    print("\nğŸ“š æ–‡æ¡£ç« èŠ‚:")
    for i, section in enumerate(document.sections[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  {i+1}. {section.title} ({section.section_type.value})")
        print(f"     é•¿åº¦: {len(section.content)} å­—ç¬¦")
        print(f"     å®ä½“æ•°: {len(section.entities)}")

    # 3. æŸ¥çœ‹è¡¨æ ¼ä¿¡æ¯
    if document.tables:
        print("\nğŸ“Š è¡¨æ ¼ä¿¡æ¯:")
        for i, table in enumerate(document.tables[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  è¡¨æ ¼ {i+1}:")
            print(f"    åˆ—æ•°: {len(table.headers)}")
            print(f"    è¡Œæ•°: {len(table.rows)}")
            if table.interpretation:
                print(f"    AIè§£è¯»: {table.interpretation[:100]}...")

    # 4. æŸ¥çœ‹ç®—æ³•ä¿¡æ¯
    if document.algorithms:
        print("\nğŸ”„ ä¸´åºŠç®—æ³•:")
        for i, algorithm in enumerate(document.algorithms):
            print(f"  ç®—æ³• {i+1}: {algorithm.title}")
            print(f"    æ­¥éª¤æ•°: {len(algorithm.steps)}")
            print(f"    è¯æ®ç­‰çº§: {algorithm.evidence_level}")


async def advanced_usage_example():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("é«˜çº§ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    # è·å–è§£æå™¨å®ä¾‹
    parser = HierarchicalMedicalParser()

    # è‡ªå®šä¹‰è§£æé…ç½®
    max_chunk_size = 600  # è‡ªå®šä¹‰åˆ†å—å¤§å°

    file_path = "examples/diabetes_guideline.docx"

    try:
        # 1. è§£ææ–‡æ¡£
        document = await parse_medical_document(file_path)

        # 2. è‡ªé€‚åº”åˆ†å—
        print("ğŸ”§ åˆ›å»ºè‡ªé€‚åº”åˆ†å—...")
        chunks = await create_document_chunks(document, max_chunk_size)

        print(f"âœ… åˆ†å—åˆ›å»ºæˆåŠŸ: {len(chunks)} ä¸ªå—")
        print(f"å¹³å‡å—å¤§å°: {sum(chunk.word_count for chunk in chunks) / len(chunks):.1f} è¯")

        # 3. åˆ†æåˆ†å—è´¨é‡
        semantic_blocks = sum(1 for chunk in chunks if chunk.semantic_boundary)
        print(f"è¯­ä¹‰è¾¹ç•Œå—: {semantic_blocks}/{len(chunks)} ({semantic_blocks/len(chunks)*100:.1f}%)")

        # 4. æŸ¥çœ‹ä¸åŒç±»å‹çš„åˆ†å—
        chunk_types = {}
        for chunk in chunks:
            chunk_type = chunk.chunk_type.value
            chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1

        print("\nğŸ“‹ åˆ†å—ç±»å‹åˆ†å¸ƒ:")
        for chunk_type, count in chunk_types.items():
            print(f"  {chunk_type}: {count} ä¸ªå—")

        # 5. æŸ¥çœ‹å®ä½“æå–ç»“æœ
        all_entities = []
        for section in document.sections:
            all_entities.extend(section.entities)

        if all_entities:
            print(f"\nğŸ¥ åŒ»å­¦å®ä½“ (å…± {len(all_entities)} ä¸ª):")

            # æŒ‰ç±»å‹ç»Ÿè®¡
            entity_types = {}
            for entity in all_entities:
                entity_type = entity.label
                entity_types[entity_type] = entity_types.get(entity_type, 0) + 1

            for entity_type, count in entity_types.items():
                print(f"  {entity_type}: {count} ä¸ª")

            # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å®ä½“
            print("\nå®ä½“ç¤ºä¾‹:")
            for entity in all_entities[:5]:
                print(f"  - {entity.text} ({entity.label}, ç½®ä¿¡åº¦: {entity.confidence:.2f})")

    except Exception as e:
        print(f"âŒ é«˜çº§è§£æå¤±è´¥: {e}")


async def evidence_analysis_example():
    """è¯æ®åˆ†æç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("è¯æ®åˆ†æç¤ºä¾‹")
    print("=" * 60)

    file_path = "examples/evidence_based_medicine.pdf"

    try:
        document = await parse_medical_document(file_path)

        # 1. è¯æ®ç­‰çº§ä½“ç³»åˆ†æ
        hierarchy = document.evidence_hierarchy
        print(f"ğŸ“š è¯æ®åˆ†çº§ç³»ç»Ÿ: {hierarchy.grading_system}")
        print(f"åˆ¶å®šä¾æ®: {hierarchy.guideline_basis}")

        print(f"\nğŸ“Š è¯æ®åˆ†å¸ƒ:")
        print(f"  é«˜è´¨é‡è¯æ® (Açº§): {len(hierarchy.primary_evidence)} é¡¹")
        print(f"  ä¸­ç­‰è´¨é‡è¯æ® (Bçº§): {len(hierarchy.secondary_evidence)} é¡¹")
        print(f"  ä¸“å®¶æ„è§ (Dçº§): {len(hierarchy.expert_opinion)} é¡¹")

        # 2. æŸ¥çœ‹å…·ä½“è¯æ®å¼•ç”¨
        if hierarchy.primary_evidence:
            print(f"\nğŸ” é«˜è´¨é‡è¯æ®ç¤ºä¾‹:")
            for i, ref in enumerate(hierarchy.primary_evidence[:3]):
                print(f"  {i+1}. {ref.citation_text}")
                print(f"     ç ”ç©¶ç±»å‹: {ref.study_type}")
                print(f"     è¯æ®ç­‰çº§: {ref.evidence_level.value}")

        # 3. ç« èŠ‚è¯æ®ç­‰çº§åˆ†æ
        print(f"\nğŸ“– ç« èŠ‚è¯æ®ç­‰çº§:")
        evidence_sections = [
            section for section in document.sections
            if section.evidence_level
        ]

        for section in evidence_sections:
            print(f"  {section.title}: {section.evidence_level.value}")

    except Exception as e:
        print(f"âŒ è¯æ®åˆ†æå¤±è´¥: {e}")


async def performance_analysis_example():
    """æ€§èƒ½åˆ†æç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("æ€§èƒ½åˆ†æç¤ºä¾‹")
    print("=" * 60)

    import time

    test_sizes = [1000, 5000, 10000, 50000]  # å­—ç¬¦æ•°

    for size in test_sizes:
        # ç”Ÿæˆæµ‹è¯•å†…å®¹
        test_content = f"""
# é«˜è¡€å‹ä¸´åºŠæŒ‡å—æµ‹è¯•æ–‡æ¡£ ({size} å­—ç¬¦)

## æ‘˜è¦
æœ¬æŒ‡å—ä¸ºæˆäººé«˜è¡€å‹çš„è¯Šæ–­å’Œç®¡ç†æä¾›å¾ªè¯åŒ»å­¦æ¨èã€‚
{'æµ‹è¯•åŒ»å­¦æ–‡æ¡£å†…å®¹ã€‚' * (size // 20)}

## æ¨èæ„è§

### 1. è¯Šæ–­æ ‡å‡†
- è¯Šå®¤è¡€å‹ â‰¥ 140/90 mmHg
- å®¶åº­è¡€å‹ â‰¥ 135/85 mmHg
- 24å°æ—¶åŠ¨æ€è¡€å‹ â‰¥ 130/80 mmHg

### 2. æ²»ç–—ç›®æ ‡
- ä¸€èˆ¬æ‚£è€…: < 140/90 mmHg
- é«˜å±æ‚£è€…: < 130/80 mmHg

### 3. è¯ç‰©æ²»ç–—
ä¸€çº¿è¯ç‰©: ACEIã€ARBã€CCBã€åˆ©å°¿å‰‚
è”åˆç”¨è¯: ä¸¤ç§æˆ–ä»¥ä¸Šä¸åŒæœºåˆ¶çš„è¯ç‰©
"""

        print(f"ğŸš€ æµ‹è¯•æ–‡æ¡£å¤§å°: {size:,} å­—ç¬¦")

        start_time = time.time()

        # æ¨¡æ‹Ÿè§£æè¿‡ç¨‹
        document = await parse_medical_document_string(test_content)

        end_time = time.time()
        duration = end_time - start_time

        print(f"  â±ï¸  è§£ææ—¶é—´: {duration:.3f} ç§’")
        print(f"  ğŸ“„ ç« èŠ‚æ•°: {len(document.sections)}")
        print(f"  ğŸ”¤ åˆ†å—æ•°: {len(await create_document_chunks(document))}")
        print(f"  ğŸ¥ å®ä½“æ•°: {sum(len(section.entities) for section in document.sections)}")

        # è®¡ç®—å¤„ç†é€Ÿåº¦
        chars_per_second = size / duration
        print(f"  âš¡ å¤„ç†é€Ÿåº¦: {chars_per_second:,.0f} å­—ç¬¦/ç§’")

        print()


async def parse_medical_document_string(content: str) -> 'MedicalDocument':
    """ä»å­—ç¬¦ä¸²è§£æåŒ»å­¦æ–‡æ¡£ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰"""
    from app.services.medical_parser import MedicalDocument, DocumentMetadata, DocumentType, SectionType
    from dataclasses import field

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
        f.write(content)
        temp_path = f.name

    try:
        # è§£ææ–‡æ¡£
        document = await parse_medical_document(temp_path)
        return document
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        os.unlink(temp_path)


async def integration_example():
    """é›†æˆä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("å·¥ä½œæµé›†æˆç¤ºä¾‹")
    print("=" * 60)

    from celery_worker.workflow_nodes.node1_medical_parser import parse_medical_guideline

    # æ¨¡æ‹Ÿå·¥ä½œæµä¸Šä¸‹æ–‡
    workflow_context = {
        "file_path": "examples/comprehensive_medical_guideline.pdf",
        "guideline_id": "guideline_001",
        "max_chunk_size": 800,
        "workflow_id": "workflow_001",
        "user_id": "user_001"
    }

    try:
        print("ğŸ”„ æ‰§è¡Œå·¥ä½œæµèŠ‚ç‚¹...")
        result = await parse_medical_guideline(
            file_path=workflow_context["file_path"],
            guideline_id=workflow_context["guideline_id"],
            max_chunk_size=workflow_context["max_chunk_size"]
        )

        if result["success"]:
            print("âœ… èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ!")
            print(f"æ–‡æ¡£ID: {result['document_id']}")
            print(f"æ€»è¯æ•°: {result['total_words']:,}")
            print(f"ç« èŠ‚æ•°: {result['sections_count']}")
            print(f"è¡¨æ ¼æ•°: {result['tables_count']}")
            print(f"ç®—æ³•æ•°: {result['algorithms_count']}")
            print(f"åˆ†å—æ•°: {result['chunks_count']}")

            # æ˜¾ç¤ºå¤„ç†æ‘˜è¦
            summary = result.get("summary", {})
            if summary and "quality_metrics" in summary:
                metrics = summary["quality_metrics"]
                print(f"\nğŸ“Š è´¨é‡æŒ‡æ ‡:")
                print(f"  è¯­ä¹‰è¾¹ç•Œæ¯”ä¾‹: {metrics['semantic_boundary_ratio']:.2f}")
                print(f"  å¹³å‡å—å¤§å°: {metrics['avg_chunk_size']:.1f} è¯")
                print(f"  æœ‰è¯æ®åˆ†çº§: {metrics['has_evidence_grading']}")
                print(f"  åŒ…å«è¡¨æ ¼: {metrics['has_tables']}")
                print(f"  åŒ…å«ç®—æ³•: {metrics['has_algorithms']}")
        else:
            print(f"âŒ èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ åŒ»å­¦æ–‡æ¡£è§£æå™¨ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    try:
        # åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
        await basic_usage_example()

        # é«˜çº§ä½¿ç”¨ç¤ºä¾‹
        await advanced_usage_example()

        # è¯æ®åˆ†æç¤ºä¾‹
        await evidence_analysis_example()

        # æ€§èƒ½åˆ†æç¤ºä¾‹
        await performance_analysis_example()

        # é›†æˆä½¿ç”¨ç¤ºä¾‹
        await integration_example()

        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ!")

    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())