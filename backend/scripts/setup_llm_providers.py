#!/usr/bin/env python3
"""
LLMæä¾›å•†è®¾ç½®è„šæœ¬
LLM Provider Setup Script
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.llm_config import get_llm_config_manager, ModelSelectionStrategy
from app.core.llm_client import get_llm_client
from app.core.config import get_settings
from app.core.logger import get_logger

logger = get_logger(__name__)


async def check_llm_health():
    """æ£€æŸ¥LLMæä¾›å•†å¥åº·çŠ¶æ€"""
    print("[AI] æ£€æŸ¥LLMæä¾›å•†å¥åº·çŠ¶æ€...")

    try:
        llm_client = await get_llm_client()
        health_result = await llm_client.health_check()

        print(f"æ€»ä½“çŠ¶æ€: {health_result['status']}")
        print("\næä¾›å•†çŠ¶æ€:")
        for provider_name, provider_status in health_result['providers'].items():
            status_icon = "[OK]" if provider_status['status'] == 'healthy' else "[FAIL]"
            print(f"  {status_icon} {provider_name}: {provider_status['status']}")
            if provider_status['status'] == 'unhealthy':
                print(f"    é”™è¯¯: {provider_status.get('error', 'Unknown error')}")
            elif 'model' in provider_status:
                print(f"    æ¨¡å‹: {provider_status['model']}")

        return health_result['status'] != 'unhealthy'

    except Exception as e:
        print(f"[FAIL] LLMå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False


async def test_llm_providers():
    """æµ‹è¯•LLMæä¾›å•†åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•LLMæä¾›å•†åŠŸèƒ½...")

    try:
        llm_client = await get_llm_client()
        config_manager = get_llm_config_manager()

        # æµ‹è¯•æ¶ˆæ¯
        test_message = "è¯·ç®€å•è§£é‡Šä»€ä¹ˆæ˜¯åŒ»å­¦æŒ‡å—ï¼Ÿ"

        print(f"æµ‹è¯•æ¶ˆæ¯: {test_message}")
        print()

        providers = config_manager.get_providers(enabled_only=True)

        for provider in providers:
            if provider.provider_type.value == 'mock':
                continue  # è·³è¿‡Mockæä¾›å•†

            print(f"æµ‹è¯•æä¾›å•†: {provider.name}")
            try:
                response = await llm_client.chat_completion(
                    messages=[{"role": "user", "content": test_message}],
                    provider=provider.name,
                    max_tokens=100
                )
                print(f"  [OK] å“åº”æˆåŠŸ: {response[:100]}...")

            except Exception as e:
                print(f"  [FAIL] å“åº”å¤±è´¥: {e}")
            print()

        return True

    except Exception as e:
        print(f"[FAIL] LLMæµ‹è¯•å¤±è´¥: {e}")
        return False


async def show_available_models():
    """æ˜¾ç¤ºå¯ç”¨æ¨¡å‹"""
    print("[LIST] å¯ç”¨æ¨¡å‹åˆ—è¡¨:")

    try:
        config_manager = get_llm_config_manager()

        # æŒ‰åˆ†ç±»æ˜¾ç¤º
        categories = ["general", "reasoning", "medical"]

        for category in categories:
            models = config_manager.get_models(category=category)
            if models:
                print(f"\nğŸ·ï¸  {category.upper()} æ¨¡å‹:")
                for model in models:
                    cost_icon = "ğŸ’°" if model.cost_per_1k_tokens > 0.01 else "ğŸ’µ"
                    tags_str = ", ".join(model.tags[:3])  # åªæ˜¾ç¤ºå‰3ä¸ªæ ‡ç­¾
                    if len(model.tags) > 3:
                        tags_str += "..."

                    print(f"  {cost_icon} {model.provider.value}:{model.name}")
                    print(f"     ğŸ“ {model.description}")
                    print(f"     ğŸ·ï¸  {tags_str} | ğŸ’µ ${model.cost_per_1k_tokens}/1K tokens")
                    print(f"     ğŸ“ ä¸Šä¸‹æ–‡: {model.context_length} tokens")

        # æ¨èæ¨¡å‹
        print(f"\n[TARGET] æ¨èæ¨¡å‹:")
        strategies = [
            ("æœ€å¿«å“åº”", ModelSelectionStrategy.fastest),
            ("æˆæœ¬æ•ˆç›Š", ModelSelectionStrategy.cost_effective),
            ("æœ€é«˜è´¨é‡", ModelSelectionStrategy.highest_quality),
            ("é•¿ä¸Šä¸‹æ–‡", ModelSelectionStrategy.long_context)
        ]

        for strategy_name, strategy_func in strategies:
            model = strategy_func()
            if model:
                print(f"  {strategy_name}: {model.provider.value}:{model.name}")
            else:
                print(f"  {strategy_name}: æ— å¯ç”¨æ¨¡å‹")

    except Exception as e:
        print(f"[FAIL] è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")


async def show_configuration():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    print("âš™ï¸  å½“å‰LLMé…ç½®:")

    try:
        settings = get_settings()
        config_manager = get_llm_config_manager()

        print(f"é»˜è®¤LLMæ¨¡å‹: {settings.DEFAULT_LLM_MODEL}")
        print(f"é«˜è´¨é‡æ¨¡å‹: {settings.HIGH_QUALITY_MODEL}")
        print(f"æˆæœ¬æ•ˆç›Šæ¨¡å‹: {settings.COST_EFFECTIVE_MODEL}")
        print(f"æœ€å¤§tokens: {settings.MAX_TOKENS_PER_REQUEST}")
        print(f"é»˜è®¤æ¸©åº¦: {settings.TEMPERATURE}")
        print()

        providers = config_manager.get_providers()
        print(f"å·²é…ç½®æä¾›å•† ({len(providers)} ä¸ª):")

        for provider in providers:
            status = "[GREEN]" if provider.enabled else "[REDIS]"
            priority = f"â­ {provider.priority}" if provider.priority <= 2 else f"  {provider.priority}"
            print(f"  {status} {priority} {provider.name} ({provider.provider_type.value})")

            if provider.base_url:
                print(f"    URL: {provider.base_url}")

            if provider.models:
                print(f"    æ¨¡å‹: {len(provider.models)} ä¸ª")

    except Exception as e:
        print(f"[FAIL] è·å–é…ç½®å¤±è´¥: {e}")


async def validate_configuration():
    """éªŒè¯é…ç½®"""
    print("[OK] éªŒè¯LLMé…ç½®...")

    try:
        config_manager = get_llm_config_manager()
        errors = config_manager.validate_config()

        if errors:
            print("[FAIL] å‘ç°é…ç½®é—®é¢˜:")
            for error in errors:
                print(f"  - {error}")
            return False
        else:
            print("[OK] é…ç½®éªŒè¯é€šè¿‡")
            return True

    except Exception as e:
        print(f"[FAIL] é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


async def save_configuration():
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        config_manager = get_llm_config_manager()
        config_path = project_root / "config" / "llm_config.json"
        config_path.parent.mkdir(exist_ok=True)

        config_manager.save_config(config_path)
        print(f"[OK] é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

    except Exception as e:
        print(f"[FAIL] ä¿å­˜é…ç½®å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("[AI] CPG2PVG-AI LLMæä¾›å•†è®¾ç½®")
    print("=" * 50)

    # æ˜¾ç¤ºå½“å‰é…ç½®
    await show_configuration()
    print()

    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    await show_available_models()
    print()

    # éªŒè¯é…ç½®
    config_valid = await validate_configuration()
    if not config_valid:
        print("\n[WARN]  é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return False
    print()

    # å¥åº·æ£€æŸ¥
    health_ok = await check_llm_health()
    print()

    # åŠŸèƒ½æµ‹è¯•
    if health_ok:
        test_ok = await test_llm_providers()
        if not test_ok:
            print("\n[WARN]  éƒ¨åˆ†LLMæä¾›å•†æµ‹è¯•å¤±è´¥")

    # ä¿å­˜é…ç½®
    await save_configuration()

    print("\n[SUCCESS] LLMæä¾›å•†è®¾ç½®å®Œæˆï¼")
    print("\n[LIST] ä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥APIå¯†é’¥é…ç½®")
    print("2. æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ•ˆæœ")
    print("3. æ ¹æ®éœ€è¦è°ƒæ•´æ¨¡å‹ä¼˜å…ˆçº§")
    print("4. ç›‘æ§ä½¿ç”¨æˆæœ¬")

    return True


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)