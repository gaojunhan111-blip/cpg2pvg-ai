#!/usr/bin/env python3
"""
Final Quality Report Generator
æœ€ç»ˆè´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class QualityReportGenerator:
    """è´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.project_root = project_root
        self.report_data = {
            "analysis_timestamp": datetime.now().isoformat(),
            "project_overview": {},
            "optimization_summary": {},
            "code_quality_metrics": {},
            "architecture_status": {},
            "recommendations": [],
            "grade": "A"
        }

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆè´¨é‡æŠ¥å‘Š"""
        print("FINAL CODE QUALITY REPORT")
        print("="*80)

        # æ”¶é›†é¡¹ç›®æ¦‚è§ˆ
        self._collect_project_overview()

        # åˆ†æä¼˜åŒ–æˆæœ
        self._analyze_optimization_results()

        # è¯„ä¼°ä»£ç è´¨é‡æŒ‡æ ‡
        self._assess_code_quality_metrics()

        # è¯„ä¼°æ¶æ„çŠ¶æ€
        self._assess_architecture_status()

        # ç”Ÿæˆå»ºè®®
        self._generate_recommendations()

        # è®¡ç®—æœ€ç»ˆè¯„åˆ†
        self._calculate_final_grade()

        # ä¿å­˜æŠ¥å‘Š
        self._save_report()

        # æ‰“å°æ‘˜è¦
        self._print_summary()

    def _collect_project_overview(self):
        """æ”¶é›†é¡¹ç›®æ¦‚è§ˆ"""
        print("\\n1. PROJECT OVERVIEW")
        print("-" * 40)

        # ç»Ÿè®¡Pythonæ–‡ä»¶
        python_files = list(self.project_root.glob("**/*.py"))
        total_files = len(python_files)

        # æŒ‰ç›®å½•åˆ†ç±»
        directories = {}
        for file_path in python_files:
            relative_path = file_path.relative_to(self.project_root)
            dir_name = str(relative_path.parts[0]) if len(relative_path.parts) > 0 else "root"
            if dir_name not in directories:
                directories[dir_name] = []
            directories[dir_name].append(str(relative_path))

        # ç»Ÿè®¡ä»£ç è¡Œæ•°
        total_lines = 0
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    total_lines += len(f.readlines())
            except:
                pass

        self.report_data["project_overview"] = {
            "total_python_files": total_files,
            "total_lines_of_code": total_lines,
            "main_directories": {
                dir_name: len(files) for dir_name, files in directories.items()
                if dir_name in ["app", "celery_worker", "scripts"]
            }
        }

        print(f"  Total Python files: {total_files}")
        print(f"  Total lines of code: {total_lines:,}")
        print(f"  Main directories:")
        for dir_name, count in self.report_data["project_overview"]["main_directories"].items():
            print(f"    {dir_name}: {count} files")

    def _analyze_optimization_results(self):
        """åˆ†æä¼˜åŒ–ç»“æœ"""
        print("\\n2. OPTIMIZATION RESULTS")
        print("-" * 40)

        # è¯»å–ä¼˜åŒ–æŠ¥å‘Š
        optimization_report_path = self.project_root / "code_optimization_report.json"
        if optimization_report_path.exists():
            with open(optimization_report_path, 'r', encoding='utf-8') as f:
                optimization_data = json.load(f)

            self.report_data["optimization_summary"] = optimization_data.get("statistics", {})
            print(f"  Files processed: {optimization_data.get('statistics', {}).get('files_processed', 0)}")
            print(f"  Long lines fixed: {optimization_data.get('statistics', {}).get('long_lines_fixed', 0)}")
            print(f"  Import issues fixed: {optimization_data.get('statistics', {}).get('import_issues_fixed', 0)}")
            print(f"  Formatting issues fixed: {optimization_data.get('statistics', {}).get('formatting_issues_fixed', 0)}")
        else:
            self.report_data["optimization_summary"] = {
                "files_processed": 0,
                "long_lines_fixed": 0,
                "import_issues_fixed": 0,
                "formatting_issues_fixed": 0
            }
            print("  Optimization report not found")

    def _assess_code_quality_metrics(self):
        """è¯„ä¼°ä»£ç è´¨é‡æŒ‡æ ‡"""
        print("\\n3. CODE QUALITY METRICS")
        print("-" * 40)

        # åŸºäºä¼˜åŒ–ç»“æœè®¡ç®—è´¨é‡æŒ‡æ ‡
        stats = self.report_data["optimization_summary"]

        # é•¿è¡Œé—®é¢˜è¯„åˆ†
        total_long_lines = stats.get("long_lines_fixed", 0)
        if total_long_lines == 0:
            long_line_score = 100
        elif total_long_lines < 20:
            long_line_score = 80
        elif total_long_lines < 50:
            long_line_score = 60
        else:
            long_line_score = 40

        # å¯¼å…¥ç»„ç»‡è¯„åˆ†
        import_issues = stats.get("import_issues_fixed", 0)
        if import_issues == 0:
            import_score = 100
        elif import_issues < 10:
            import_score = 85
        elif import_issues < 20:
            import_score = 70
        else:
            import_score = 50

        # æ ¼å¼åŒ–é—®é¢˜è¯„åˆ†
        format_issues = stats.get("formatting_issues_fixed", 0)
        if format_issues == 0:
            format_score = 100
        elif format_issues < 30:
            format_score = 80
        elif format_issues < 60:
            format_score = 60
        else:
            format_score = 40

        # ç»¼åˆä»£ç è´¨é‡è¯„åˆ†
        overall_quality = (long_line_score * 0.4 + import_score * 0.3 + format_score * 0.3)

        self.report_data["code_quality_metrics"] = {
            "long_line_score": long_line_score,
            "import_organization_score": import_score,
            "formatting_score": format_score,
            "overall_quality_score": overall_quality
        }

        print(f"  Long line compliance: {long_line_score}/100")
        print(f"  Import organization: {import_score}/100")
        print(f"  Code formatting: {format_score}/100")
        print(f"  Overall quality: {overall_quality:.1f}/100")

    def _assess_architecture_status(self):
        """è¯„ä¼°æ¶æ„çŠ¶æ€"""
        print("\\n4. ARCHITECTURE STATUS")
        print("-" * 40)

        # æ£€æŸ¥å…³é”®ç»„ä»¶
        components = {
            "Core Services": {
                "files": [
                    "app/services/medical_parser.py",
                    "app/services/multimodal_processor.py",
                    "app/services/knowledge_graph.py",
                    "app/services/intelligent_agent.py",
                    "app/services/medical_agents.py",
                    "app/services/agent_orchestrator.py"
                ],
                "weight": 0.3
            },
            "Data Models": {
                "files": [
                    "app/models/knowledge_graph.py",
                    "app/models/intelligent_agent.py",
                    "app/models/medical_document.py",
                    "app/models/multimodal_content.py"
                ],
                "weight": 0.2
            },
            "Workflow Nodes": {
                "files": [
                    "celery_worker/workflow_nodes/node1_medical_parser.py",
                    "celery_worker/workflow_nodes/node2_multimodal_processor.py",
                    "celery_worker/workflow_nodes/node3_knowledge_graph.py",
                    "celery_worker/workflow_nodes/node4_intelligent_agents.py"
                ],
                "weight": 0.3
            },
            "Configuration": {
                "files": [
                    "app/core/config.py",
                    "app/core/database.py",
                    "app/core/logger.py"
                ],
                "weight": 0.1
            },
            "Tests": {
                "files": [
                    "scripts/test_core_services_ascii.py",
                    "scripts/test_architecture_validation.py"
                ],
                "weight": 0.1
            }
        }

        total_weight = 0
        architecture_score = 0

        for component_name, component_data in components.items():
            existing_files = 0
            for file_path in component_data["files"]:
                if (self.project_root / file_path).exists():
                    existing_files += 1

            component_score = (existing_files / len(component_data["files"])) * 100
            component_weight = component_data["weight"]

            architecture_score += component_score * component_weight
            total_weight += component_weight

            print(f"  {component_name}: {existing_files}/{len(component_data['files'])} files ({component_score:.0f}%)")

        # æ ‡å‡†åŒ–è¯„åˆ†
        if total_weight > 0:
            architecture_score = architecture_score / total_weight
        else:
            architecture_score = 0

        self.report_data["architecture_status"] = {
            "overall_architecture_score": architecture_score,
            "component_details": {
                name: {
                    "files_found": sum(1 for f in data["files"] if (self.project_root / f).exists()),
                    "total_files": len(data["files"]),
                    "score": (sum(1 for f in data["files"] if (self.project_root / f).exists()) / len(data["files"])) * 100
                }
                for name, data in components.items()
            }
        }

        print(f"  Overall architecture: {architecture_score:.1f}/100")

    def _generate_recommendations(self):
        """ç”Ÿæˆå»ºè®®"""
        print("\\n5. RECOMMENDATIONS")
        print("-" * 40)

        recommendations = []

        # åŸºäºä»£ç è´¨é‡è¯„åˆ†çš„å»ºè®®
        quality_metrics = self.report_data["code_quality_metrics"]
        if quality_metrics["overall_quality_score"] < 80:
            recommendations.append({
                "category": "Code Quality",
                "priority": "High",
                "description": "Further code quality improvements needed",
                "actions": ["Continue refactoring long functions", "Improve code documentation", "Add comprehensive tests"]
            })
        elif quality_metrics["overall_quality_score"] < 90:
            recommendations.append({
                "category": "Code Quality",
                "priority": "Medium",
                "description": "Minor code quality improvements recommended",
                "actions": ["Add more inline comments", "Improve variable naming", "Enhance error handling"]
            })

        # åŸºäºæ¶æ„çŠ¶æ€çš„å»ºè®®
        arch_score = self.report_data["architecture_status"]["overall_architecture_score"]
        if arch_score < 80:
            recommendations.append({
                "category": "Architecture",
                "priority": "High",
                "description": "Architecture needs attention",
                "actions": ["Complete missing components", "Improve system integration", "Add proper error handling"]
            })
        elif arch_score < 95:
            recommendations.append({
                "category": "Architecture",
                "priority": "Low",
                "description": "Minor architecture improvements possible",
                "actions": ["Add performance monitoring", "Implement caching strategies", "Enhance logging"]
            })

        # é€šç”¨å»ºè®®
        recommendations.append({
            "category": "Best Practices",
            "priority": "Medium",
            "description": "Follow Python best practices",
            "actions": ["Use type hints consistently", "Implement proper logging", "Add comprehensive unit tests"]
        })

        recommendations.append({
            "category": "Documentation",
            "priority": "High",
            "description": "Improve project documentation",
            "actions": ["Add API documentation", "Create user guides", "Document configuration options"]
        })

        self.report_data["recommendations"] = recommendations

        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec['category']} ({rec['priority']})")
            print(f"     {rec['description']}")
            print(f"     Actions: {', '.join(rec['actions'])}")

    def _calculate_final_grade(self):
        """è®¡ç®—æœ€ç»ˆè¯„åˆ†"""
        print("\\n6. FINAL ASSESSMENT")
        print("-" * 40)

        # è®¡ç®—ç»¼åˆè¯„åˆ†
        quality_score = self.report_data["code_quality_metrics"]["overall_quality_score"]
        architecture_score = self.report_data["architecture_status"]["overall_architecture_score"]

        # æƒé‡åˆ†é…
        final_score = quality_score * 0.6 + architecture_score * 0.4

        # ç¡®å®šç­‰çº§
        if final_score >= 95:
            grade = "A+"
            status = "Excellent - Production Ready"
        elif final_score >= 90:
            grade = "A"
            status = "Excellent - Ready for Production"
        elif final_score >= 85:
            grade = "A-"
            status = "Very Good - Minor Improvements Needed"
        elif final_score >= 80:
            grade = "B+"
            status = "Good - Some Improvements Needed"
        elif final_score >= 75:
            grade = "B"
            status = "Above Average - Moderate Improvements Needed"
        elif final_score >= 70:
            grade = "B-"
            status = "Average - Significant Improvements Needed"
        elif final_score >= 65:
            grade = "C+"
            status = "Below Average - Major Improvements Needed"
        elif final_score >= 60:
            grade = "C"
            status = "Fair - Extensive Work Required"
        else:
            grade = "F"
            status = "Poor - Complete Redesign Needed"

        self.report_data["grade"] = grade
        self.report_data["final_score"] = final_score
        self.report_data["status"] = status

        print(f"  Final Score: {final_score:.1f}/100")
        print(f"  Grade: {grade}")
        print(f"  Status: {status}")

    def _save_report(self):
        """ä¿å­˜æŠ¥å‘Š"""
        report_path = self.project_root / "final_quality_report.json"

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(self.report_data, f, indent=2, ensure_ascii=False, default=str)

            print(f"\\nğŸ“„ Detailed report saved to: {report_path.relative_to(self.project_root)}")
        except Exception as e:
            print(f"\\nâš ï¸ Failed to save report: {e}")

    def _print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        print("\\n" + "="*80)
        print("CODE OPTIMIZATION AND QUALITY IMPROVEMENT SUMMARY")
        print("="*80)

        print(f"\\nğŸ¯ FINAL GRADE: {self.report_data['grade']}")
        print(f"ğŸ“Š FINAL SCORE: {self.report_data['final_score']:.1f}/100")
        print(f"ğŸ“‹ STATUS: {self.report_data['status']}")

        print(f"\\nğŸ“ˆ IMPROVEMENTS MADE:")
        stats = self.report_data["optimization_summary"]
        print(f"   â€¢ Files processed: {stats.get('files_processed', 0)}")
        print(f"   â€¢ Long lines fixed: {stats.get('long_lines_fixed', 0)}")
        print(f"   â€¢ Import issues resolved: {stats.get('import_issues_fixed', 0)}")
        print(f"   â€¢ Formatting issues fixed: {stats.get('formatting_issues_fixed', 0)}")
        print(f"   â€¢ Total fixes applied: {sum(stats.values())}")

        print(f"\\nğŸ—ï¸ ARCHITECTURE STATUS:")
        arch_details = self.report_data["architecture_status"]["component_details"]
        for component, details in arch_details.items():
            status = "âœ“" if details["score"] >= 90 else "âš " if details["score"] >= 70 else "âœ—"
            print(f"   {status} {component}: {details['files_found']}/{details['total_files']} files")

        print(f"\\nğŸ“‹ KEY RECOMMENDATIONS:")
        high_priority = [rec for rec in self.report_data["recommendations"] if rec["priority"] == "High"]
        if high_priority:
            for rec in high_priority[:3]:
                print(f"   â€¢ {rec['description']}")
        else:
            print("   â€¢ No high-priority issues - Great work!")

        print(f"\\nğŸš€ NEXT STEPS:")
        grade = self.report_data["grade"]
        if grade.startswith("A"):
            print("   âœ“ System is ready for production deployment")
            print("   âœ“ Consider implementing automated CI/CD pipeline")
            print("   âœ“ Set up comprehensive monitoring and logging")
        elif grade.startswith("B"):
            print("   â€¢ Address the high-priority recommendations")
            print("   â€¢ Add comprehensive test coverage")
            print("   â€¢ Improve documentation and user guides")
        else:
            print("   â€¢ Major refactoring required before production")
            print("   â€¢ Focus on core architecture improvements")
            print("   â€¢ Implement proper error handling and logging")


def main():
    """ä¸»å‡½æ•°"""
    try:
        generator = QualityReportGenerator()
        generator.generate_comprehensive_report()

    except KeyboardInterrupt:
        print("\\nReport generation interrupted by user")
    except Exception as e:
        print(f"\\nReport generation failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()