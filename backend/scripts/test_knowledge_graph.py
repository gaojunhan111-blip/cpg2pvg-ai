#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°±æµ‹è¯•è„šæœ¬
Knowledge Graph Test Script
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def print_colored(message: str, color: str = "white"):
    """æ‰“å°å½©è‰²æ¶ˆæ¯"""
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "purple": "\033[95m",
        "cyan": "\033[96m",
        "white": "\033[97m",
        "reset": "\033[0m"
    }
    print(f"{colors.get(color, colors['white'])}{message}{colors['reset']}")


async def test_knowledge_graph():
    """æµ‹è¯•çŸ¥è¯†å›¾è°±"""
    print_colored("ğŸ§  æµ‹è¯•åŸºäºçŸ¥è¯†å›¾è°±çš„è¯­ä¹‰ç†è§£", "cyan")
    print("=" * 60)

    try:
        # å¯¼å…¥å¿…è¦æ¨¡å—
        from app.services.knowledge_graph import (
            MedicalKnowledgeGraph, EnhancedContent, ProcessingConfig,
            MedicalEntity, EntityType, LinkedEntity, ClinicalRelationship,
            ClinicalContext, MedicalOntology
        )
        from app.services.multimodal_processor import ProcessedContent, TextProcessingResult, ProcessingStatus
        print_colored("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ", "green")

        # åˆ›å»ºæµ‹è¯•çš„ProcessedContent
        test_processed_content = create_test_processed_content()
        print_colored("âœ… æµ‹è¯•å†…å®¹åˆ›å»ºæˆåŠŸ", "green")

        # åˆ›å»ºçŸ¥è¯†å›¾è°±é…ç½®
        config = {
            "min_entity_confidence": 0.4,
            "max_entities_per_type": 20,
            "enable_ontology_linking": True,
            "enable_relationship_inference": True,
            "enable_context_building": True
        }
        print_colored("âœ… çŸ¥è¯†å›¾è°±é…ç½®åˆ›å»ºæˆåŠŸ", "green")

        # åˆ›å»ºçŸ¥è¯†å›¾è°±å¤„ç†å™¨
        kg = MedicalKnowledgeGraph(config)
        print_colored("âœ… çŸ¥è¯†å›¾è°±å¤„ç†å™¨åˆ›å»ºæˆåŠŸ", "green")

        # éªŒè¯æœ¬ä½“åŠ è½½
        if kg.ontology and kg.ontology.total_concepts > 0:
            print_colored(f"âœ… æœ¬ä½“åŠ è½½æˆåŠŸ: {kg.ontology.total_concepts}ä¸ªæ¦‚å¿µ", "green")
        else:
            print_colored("âš ï¸ æœ¬ä½“åŠ è½½å¯èƒ½å¤±è´¥", "yellow")

        # æ‰§è¡Œè¯­ä¹‰ç†è§£å¢å¼º
        print_colored("ğŸ”„ å¼€å§‹è¯­ä¹‰ç†è§£å¢å¼ºæµ‹è¯•...", "yellow")
        start_time = asyncio.get_event_loop().time()

        enhanced_content = await kg.enhance_semantic_understanding(test_processed_content)

        end_time = asyncio.get_event_loop().time()
        processing_time = end_time - start_time

        print_colored(f"âœ… è¯­ä¹‰ç†è§£å¢å¼ºå®Œæˆï¼Œè€—æ—¶ {processing_time:.2f} ç§’", "green")

        # éªŒè¯ç»“æœ
        await validate_knowledge_graph_results(enhanced_content)

        return True

    except Exception as e:
        print_colored(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}", "red")
        import traceback
        traceback.print_exc()
        return False


def create_test_processed_content():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ProcessedContent"""
    # å¯¼å…¥å¿…è¦çš„ç±»
    from app.services.multimodal_processor import ProcessedContent, TextProcessingResult, ProcessingStatus
    from app.services.knowledge_graph import EntityType

    # åˆ›å»ºæ–‡æœ¬å¤„ç†ç»“æœ
    text_results = [
        TextProcessingResult(
            text_result_id="text_001",
            section_id="section_diagnosis",
            section_type="recommendations",
            original_content="2å‹ç³–å°¿ç—…æ‚£è€…çš„è¡€ç³–æ§åˆ¶ç›®æ ‡",
            processed_content="å¯¹äº2å‹ç³–å°¿ç—…æ‚£è€…ï¼Œå»ºè®®å°†ç³–åŒ–è¡€çº¢è›‹ç™½æ§åˆ¶åœ¨7%ä»¥ä¸‹ã€‚è¿™ä¸ªç›®æ ‡é€‚ç”¨äºå¤§å¤šæ•°æˆå¹´æ‚£è€…ã€‚",
            summary="è¡€ç³–æ§åˆ¶ç›®æ ‡ä¸ºHbA1c < 7%",
            key_points=["è¡€ç³–æ§åˆ¶ç›®æ ‡", "HbA1c < 7%", "é€‚ç”¨äºå¤§å¤šæ•°æ‚£è€…"],
            medical_entities=[
                {"text": "2å‹ç³–å°¿ç—…", "type": "disease", "confidence": 0.9},
                {"text": "ç³–åŒ–è¡€çº¢è›‹ç™½", "type": "lab_test", "confidence": 0.8}
            ],
            clinical_concepts=["diabetes management", "glycemic control"],
            status=ProcessingStatus.COMPLETED,
            processing_log=["Text processing completed"]
        ),
        TextProcessingResult(
            text_result_id="text_002",
            section_id="section_treatment",
            section_type="treatment",
            original_content="ä½¿ç”¨äºŒç”²åŒèƒä½œä¸ºä¸€çº¿æ²»ç–—è¯ç‰©ï¼Œå¿…è¦æ—¶åŠ ç”¨èƒ°å²›ç´ æ²»ç–—ã€‚",
            processed_content="ä½¿ç”¨äºŒç”²åŒèƒä½œä¸ºä¸€çº¿æ²»ç–—è¯ç‰©ï¼Œå¿…è¦æ—¶åŠ ç”¨èƒ°å²›ç´ æ²»ç–—ã€‚",
            summary="ä¸€çº¿è¯ç‰©ä¸ºäºŒç”²åŒèƒï¼Œå¿…è¦æ—¶åŠ èƒ°å²›ç´ ",
            key_points=["äºŒç”²åŒèƒ", "ä¸€çº¿æ²»ç–—", "å¿…è¦æ—¶èƒ°å²›ç´ "],
            medical_entities=[
                {"text": "äºŒç”²åŒèƒ", "type": "medication", "confidence": 0.9},
                {"text": "èƒ°å²›ç´ ", "type": "medication", "confidence": 0.8}
            ],
            clinical_concepts=["pharmacological therapy"],
            status=ProcessingStatus.COMPLETED,
            processing_log=["Text processing completed"]
        )
    ]

    # åˆ›å»ºProcessedContentå®ä¾‹
    from app.services.multimodal_processor import ProcessedContent

    return ProcessedContent(
        content_id="test_processed_001",
        source_document_id="test_doc_001",
        text_results=text_results,
        processed_tables=[],
        processed_algorithms=[],
        integrated_summary="2å‹ç³–å°¿ç—…çš„æ²»ç–—ç®¡ç†ï¼ŒåŒ…æ‹¬è¡€ç³–ç›®æ ‡å’Œè¯ç‰©æ²»ç–—æ–¹æ¡ˆ",
        key_clinical_insights=["HbA1cç›®æ ‡7%", "äºŒç”²åŒèƒä¸€çº¿ç”¨è¯"],
        content_statistics={},
        total_processing_time=0.0,
        total_tokens_used=0,
        total_cost_estimate=0.0,
        overall_quality_score=0.85,
        completeness_score=0.9,
        status="completed",
        processing_log=["Test content created"]
    )


async def validate_knowledge_graph_results(enhanced_content):
    """éªŒè¯çŸ¥è¯†å›¾è°±ç»“æœ"""
    print_colored("\nğŸ“Š éªŒè¯çŸ¥è¯†å›¾è°±ç»“æœ", "blue")
    print("-" * 40)

    # åŸºæœ¬ä¿¡æ¯
    print(f"å†…å®¹ID: {enhanced_content.content_id}")
    print(f"å¤„ç†æ—¶é—´: {enhanced_content.processing_time:.2f}ç§’")
    print(f"æ€»ä½“è´¨é‡: {enhanced_content.overall_quality:.2f}")

    # å®ä½“åˆ†æ
    print(f"\nğŸ·ï¸ åŒ»å­¦å®ä½“åˆ†æ:")
    print(f"  æå–å®ä½“æ•°: {len(enhanced_content.entities)}")
    print(f"  é“¾æ¥å®ä½“æ•°: {len([e for e in enhanced_content.entities if e.link_confidence > 0])}")
    print(f"  å®ä½“ç±»å‹åˆ†å¸ƒ: {enhanced_content.entity_counts}")

    # å®ä½“è´¨é‡æ£€æŸ¥
    high_confidence_entities = [e for e in enhanced_content.entities if e.link_confidence > 0.8]
    print(f"  é«˜ç½®ä¿¡åº¦å®ä½“: {len(high_confidence_entities)}")

    # æ˜¾ç¤ºå‰å‡ ä¸ªå®ä½“è¯¦æƒ…
    if enhanced_content.entities:
        print(f"\n  å‰5ä¸ªå®ä½“è¯¦æƒ…:")
        for i, linked_entity in enumerate(enhanced_content.entities[:5]):
            entity = linked_entity.entity
            print(f"    {i+1}. {entity.text} ({entity.entity_type.value})")
            print(f"       ç½®ä¿¡åº¦: {entity.extraction_confidence:.2f}")
            print(f"       é“¾æ¥ç½®ä¿¡åº¦: {linked_entity.link_confidence:.2f}")
            if linked_entity.best_match:
                print(f"       æœ¬ä½“åŒ¹é…: {linked_entity.best_match.get('preferred_name', 'N/A')}")

    # å…³ç³»åˆ†æ
    print(f"\nğŸ”— ä¸´åºŠå…³ç³»åˆ†æ:")
    print(f"  å…³ç³»æ•°: {len(enhanced_content.relationships)}")
    print(f"  å…³ç³»ç±»å‹åˆ†å¸ƒ: {enhanced_content.relationship_counts}")

    # æ˜¾ç¤ºå‰å‡ ä¸ªå…³ç³»
    if enhanced_content.relationships:
        print(f"\n  å‰5ä¸ªå…³ç³»:")
        for i, rel in enumerate(enhanced_content.relationships[:5]):
            print(f"    {i+1}. {rel.source_entity.entity.text} --{rel.relationship_type.value}--> {rel.target_entity.entity.text}")
            print(f"       ç½®ä¿¡åº¦: {rel.confidence.value}")
            print(f"       å¼ºåº¦: {rel.strength:.2f}")

    # ä¸´åºŠä¸Šä¸‹æ–‡åˆ†æ
    if enhanced_content.clinical_context:
        context = enhanced_content.clinical_context
        print(f"\nğŸ¥ ä¸´åºŠä¸Šä¸‹æ–‡åˆ†æ:")
        print(f"  ä¸Šä¸‹æ–‡å·²æ„å»º: æ˜¯")
        if context.primary_condition:
            print(f"  ä¸»è¦ç–¾ç—…: {context.primary_condition.entity.text}")
        print(f"  é£é™©å› ç´ æ•°: {len(context.risk_factors)}")
        print(f"  æ¨èæ•°: {len(context.recommendations)}")
        print(f"  å®‰å…¨è­¦æŠ¥æ•°: {len(context.warnings)}")
        print(f"  å®Œæ•´æ€§åˆ†æ•°: {context.completeness_score:.2f}")
        print(f"  ç½®ä¿¡åº¦åˆ†æ•°: {context.confidence_score:.2f}")
    else:
        print(f"\nğŸ¥ ä¸´åºŠä¸Šä¸‹æ–‡åˆ†æ:")
        print(f"  ä¸Šä¸‹æ–‡å·²æ„å»º: å¦")

    # è´¨é‡æŒ‡æ ‡
    print(f"\nğŸ“ˆ è´¨é‡æŒ‡æ ‡:")
    print(f"  æå–è´¨é‡: {enhanced_content.extraction_quality:.2f}")
    print(f"  é“¾æ¥è´¨é‡: {enhanced_content.linking_quality:.2f}")
    print(f"  æ¨ç†è´¨é‡: {enhanced_content.inference_quality:.2f}")

    # å¢å¼ºåŠŸèƒ½
    print(f"\nğŸš€ å¢å¼ºåŠŸèƒ½:")
    print(f"  è¯­ä¹‰æ‘˜è¦: {'âœ“' if enhanced_content.semantic_summary else 'âœ—'}")
    print(f"  å…³é”®æ´å¯Ÿ: {len(enhanced_content.key_insights)}")
    print(f"  ä¸´åºŠæ¨è: {len(enhanced_content.clinical_recommendations)}")
    print(f"  å®‰å…¨è­¦æŠ¥: {len(enhanced_content.safety_alerts)}")

    # æ˜¾ç¤ºå…³é”®å†…å®¹
    if enhanced_content.semantic_summary:
        print(f"\nğŸ“ è¯­ä¹‰æ‘˜è¦:")
        print(f"  {enhanced_content.semantic_summary}")

    if enhanced_content.key_insights:
        print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
        for i, insight in enumerate(enhanced_content.key_insights):
            print(f"  {i+1}. {insight}")

    if enhanced_content.clinical_recommendations:
        print(f"\nğŸ’Š ä¸´åºŠæ¨è:")
        for i, rec in enumerate(enhanced_content.clinical_recommendations):
            print(f"  {i+1}. {rec}")

    if enhanced_content.safety_alerts:
        print(f"\nâš ï¸ å®‰å…¨è­¦æŠ¥:")
        for i, alert in enumerate(enhanced_content.safety_alerts):
            print(f"  {i+1}. {alert}")

    # éªŒè¯æˆåŠŸæ ‡å‡†
    success_criteria = [
        len(enhanced_content.entities) > 0,
        len(enhanced_content.entities) == len(enhanced_content.entity_counts),
        enhanced_content.overall_quality > 0.5,
        enhanced_content.processing_time > 0
    ]

    print(f"\nâœ… éªŒè¯æ ‡å‡†æ£€æŸ¥:")
    passed = 0
    total = len(success_criteria)

    for criterion, description in success_criteria:
        status = "PASS" if criterion else "FAIL"
        color = "green" if criterion else "red"
        print_colored(f"  [{status}] {description}", color)
        if criterion:
            passed += 1

    print(f"\nğŸ“Š æ€»ä½“éªŒè¯ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print_colored("ğŸ‰ æ‰€æœ‰éªŒè¯æ ‡å‡†éƒ½é€šè¿‡ï¼", "green")
    else:
        print_colored(f"âš ï¸ {total - passed} é¡¹éªŒè¯æ ‡å‡†æœªé€šè¿‡", "yellow")


async def test_ontology_components():
    """æµ‹è¯•æœ¬ä½“ç»„ä»¶"""
    print_colored("\nğŸ§ª æµ‹è¯•æœ¬ä½“ç»„ä»¶", "purple")
    print("-" * 40)

    try:
        from app.services.knowledge_graph import MedicalKnowledgeGraph, MedicalOntology, OntologySource

        # åˆ›å»ºçŸ¥è¯†å›¾è°±å®ä¾‹
        kg = MedicalKnowledgeGraph()
        print_colored("âœ… çŸ¥è¯†å›¾è°±å®ä¾‹åˆ›å»ºæˆåŠŸ", "green")

        # éªŒè¯æœ¬ä½“
        if kg.ontology:
            print_colored(f"âœ… æœ¬ä½“åŠ è½½æˆåŠŸ: {kg.ontology.name}", "green")
            print_colored(f"   æ¦‚å¿µæ•°é‡: {kg.ontology.total_concepts}", "green")
            print_colored(f"   å…³ç³»æ•°é‡: {kg.ontology.total_relationships}", "green")
            print_colored(f"   æœ¬ä½“æ¥æº: {kg.ontology.source.value}", "green")

            # éªŒè¯æ¦‚å¿µæŸ¥æ‰¾
            test_concepts = ["diabetes", "metformin", "hypertension"]
            for concept in test_concepts:
                concept_id = kg.ontology.find_concept(concept)
                if concept_id:
                    concept_data = kg.ontology.get_concept_data(concept_id)
                    print_colored(f"   âœ… æ‰¾åˆ°æ¦‚å¿µ '{concept}': {concept_data.get('preferred_name', 'N/A')}", "green")
                else:
                    print_colored(f"   âš ï¸ æœªæ‰¾åˆ°æ¦‚å¿µ: {concept}", "yellow")

        return True

    except Exception as e:
        print_colored(f"âŒ æœ¬ä½“ç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}", "red")
        return False


async def test_entity_extraction():
    """æµ‹è¯•å®ä½“æå–"""
    print_colored("\nğŸ” æµ‹è¯•å®ä½“æå–", "purple")
    print("-" * 40)

    try:
        from app.services.knowledge_graph import MedicalKnowledgeGraph, MedicalEntity, EntityType

        # åˆ›å»ºçŸ¥è¯†å›¾è°±å®ä¾‹
        kg = MedicalKnowledgeGraph()
        print_colored("âœ… çŸ¥è¯†å›¾è°±å®ä¾‹åˆ›å»ºæˆåŠŸ", "green")

        # æµ‹è¯•è§„åˆ™æå–
        test_text = "Patient with Type 2 Diabetes mellitus treated with metformin and insulin."
        print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")

        # æ¨¡æ‹Ÿå†…å®¹æ®µ
        content_segments = [(test_text, "test_segment", "test")]

        # æå–å®ä½“
        rule_entities = await kg._extract_entities_with_rules(content_segments)
        print_colored(f"  è§„åˆ™æå–: {len(rule_entities)} ä¸ªå®ä½“")

        # æ¨¡å‹æå–
        model_entities = await kg._extract_entities_with_model(content_segments)
        print_colored(f"  æ¨¡å‹æå–: {len(model_entities)} ä¸ªå®ä½“")

        # èåˆå®ä½“
        merged_entities = kg._merge_entities(rule_entities, model_entities)
        print_colored(f"  èåˆå: {len(merged_entities)} ä¸ªå®ä½“")

        # æ˜¾ç¤ºæå–çš„å®ä½“
        if merged_entities:
            print_colored("  æå–çš„å®ä½“:")
            for entity in merged_entities:
                print(f"    - {entity.text} ({entity.entity_type.value}) - ç½®ä¿¡åº¦: {entity.extraction_confidence:.2f}")

        return len(merged_entities) > 0

    except Exception as e:
        print_colored(f"âŒ å®ä½“æå–æµ‹è¯•å¤±è´¥: {str(e)}", "red")
        return False


async def test_ontology_linking():
    """æµ‹è¯•æœ¬ä½“é“¾æ¥"""
    print_colored("\nğŸ”— æµ‹è¯•æœ¬ä½“é“¾æ¥", "purple")
    print("-" - 40)

    try:
        from app.services.knowledge_graph import MedicalKnowledgeGraph, MedicalEntity, EntityType

        # åˆ›å»ºçŸ¥è¯†å›¾è°±å®ä¾‹
        kg = MedicalKnowledgeGraph()
        print_colored("âœ… çŸ¥è¯†å›¾è°±å®ä¾‹åˆ›å»ºæˆåŠŸ", "green")

        # åˆ›å»ºæµ‹è¯•å®ä½“
        test_entities = [
            MedicalEntity(
                text="Type 2 Diabetes",
                entity_type=EntityType.DISEASE,
                extraction_confidence=0.8
            ),
            MedicalEntity(
                text="Metformin",
                entity_type=EntityType.MEDICATION,
                extraction_confidence=0.9
            ),
            MedicalEntity(
                text="Hypertension",
                entity_type=EntityType.DISEASE,
                extraction_confidence=0.7
            )
        ]
        print_colored(f"  åˆ›å»ºæµ‹è¯•å®ä½“: {len(test_entities)} ä¸ª", "green")

        # é“¾æ¥åˆ°æœ¬ä½“
        linked_entities = await kg._link_to_ontology(test_entities)
        print_colored(f"  æœ¬ä½“é“¾æ¥å®Œæˆ: {len(linked_entities)} ä¸ªå®ä½“")

        # åˆ†æé“¾æ¥ç»“æœ
        linked_count = 0
        high_confidence_count = 0

        for linked_entity in linked_entities:
            if linked_entity.best_match:
                linked_count += 1
                if linked_entity.link_confidence > 0.7:
                    high_confidence_count += 1

                entity = linked_entity.entity
                match = linked_entity.best_match
                print(f"    - {entity.text} -> {match.get('preferred_name', 'N/A')} (ç½®ä¿¡åº¦: {linked_entity.link_confidence:.2f})")

        print_colored(f"  æˆåŠŸé“¾æ¥: {linked_count}/{len(test_entities)}")
        print_colored(f"  é«˜ç½®ä¿¡åº¦é“¾æ¥: {high_confidence_count}/{len(test_entities)}")

        return linked_count > 0

    except Exception as e:
        print_colored(f"âŒ æœ¬ä½“é“¾æ¥æµ‹è¯•å¤±è´¥: {str(e)}", "red")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print_colored("ğŸ§  çŸ¥è¯†å›¾è°±é›†æˆæµ‹è¯•", "cyan")
    print("=" * 60)

    success_count = 0
    total_tests = 4

    # æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    print_colored("\nğŸ“‹ æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½æµ‹è¯•", "blue")
    if await test_knowledge_graph():
        success_count += 1

    # æµ‹è¯•2: æœ¬ä½“ç»„ä»¶æµ‹è¯•
    print_colored("\nğŸ“‹ æµ‹è¯•2: æœ¬ä½“ç»„ä»¶æµ‹è¯•", "blue")
    if await test_ontology_components():
        success_count += 1

    # æµ‹è¯•3: å®ä½“æå–æµ‹è¯•
    print_colored("\nğŸ“‹ æµ‹è¯•3: å®ä½“æå–æµ‹è¯•", "blue")
    if await test_entity_extraction():
        success_count += 1

    # æµ‹è¯•4: æœ¬ä½“é“¾æ¥æµ‹è¯•
    print_colored("\nğŸ“‹ æµ‹è¯•4: æœ¬ä½“é“¾æ¥æµ‹è¯•", "blue")
    if await test_ontology_linking():
        success_count += 1

    # æ€»ç»“
    print_colored("\n" + "=" * 60, "cyan")
    print_colored("ğŸ“Š æµ‹è¯•æ€»ç»“", "cyan")
    print(f"  é€šè¿‡: {success_count}/{total_tests}")

    if success_count == total_tests:
        print_colored("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼çŸ¥è¯†å›¾è°±ç³»ç»Ÿå·¥ä½œæ­£å¸¸", "green")
        print_colored("\nğŸ“‹ ä¸‹ä¸€æ­¥:", "cyan")
        print("  1. è¿è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•")
        print("  2. é›†æˆåˆ°å·¥ä½œæµç³»ç»Ÿ")
        print("  3. å¼€å§‹ä¸´åºŠæ–‡æ¡£è¯­ä¹‰ç†è§£")
    else:
        print_colored(f"âš ï¸ {total_tests - success_count} ä¸ªæµ‹è¯•å¤±è´¥", "yellow")
        print_colored("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜", "yellow")

    return success_count == total_tests


if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nTest interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"Test failed with error: {str(e)}")
        sys.exit(1)